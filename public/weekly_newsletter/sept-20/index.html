<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Newsletter: Sep 20th | Pk blog</title>
<meta name=keywords content="AI - Newsletter"><meta name=description content="Weekly update on AI/ML - Sept 13th - Sept 20th"><meta name=author content="Me"><link rel=canonical href=https://canonical.url/to/page><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/weekly_newsletter/sept-20/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Weekly Newsletter: Sep 20th"><meta property="og:description" content="Weekly update on AI/ML - Sept 13th - Sept 20th"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/weekly_newsletter/sept-20/"><meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E"><meta property="article:section" content="weekly_newsletter"><meta property="article:published_time" content="2020-09-15T11:30:03+00:00"><meta property="article:modified_time" content="2020-09-15T11:30:03+00:00"><meta property="og:site_name" content="PK's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:title content="Weekly Newsletter: Sep 20th"><meta name=twitter:description content="Weekly update on AI/ML - Sept 13th - Sept 20th"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Weekly_newsletters","item":"http://localhost:1313/weekly_newsletter/"},{"@type":"ListItem","position":2,"name":"Weekly Newsletter: Sep 20th","item":"http://localhost:1313/weekly_newsletter/sept-20/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Newsletter: Sep 20th","name":"Weekly Newsletter: Sep 20th","description":"Weekly update on AI/ML - Sept 13th - Sept 20th","keywords":["AI - Newsletter"],"articleBody":"AI Newsletter - Latest Developments in Models, Research, and More Highlight: Qwen2.5 Family - A Comprehensive Release of AI Models The Qwen team has unveiled their largest release ever, featuring a wide range of models for various applications.\nKey Features: Qwen2.5: Models ranging from 0.5B to 72B parameters Qwen2.5-Coder: Specialized models for coding tasks (1.5B, 7B, 32B) Qwen2.5-Math: Models optimized for mathematical reasoning (1.5B, 7B, 72B) Qwen2-VL-72B: Open-sourced multimodal model Over 100 model variants, including quantized versions (GPTQ, AWQ, GGUF) Competitive performance against proprietary models Apache 2.0 license for most open-source models The Qwen2.5-72B-Instruct model demonstrates competitive performance against proprietary models and outperforms most open-source models in various benchmark evaluations.\nModels 1. Qwen2.5 Family 14B and 32B models outperform predecessor Qwen2-72B-Instruct Compact 3B model achieves 68 on MMLU, surpassing Qwen1.5-14B Qwen2.5-Coder shows competitive performance against larger code LLMs Qwen2.5-Math supports both English and Chinese, with improved reasoning capabilities 2. Mistral AI’s Pixtral 12B Natively multimodal model with 400M parameter vision encoder Supports multiple images in 128k token context window Achieves 52.5% on MMMU reasoning benchmark Excels in instruction following, chart understanding, and image-to-code generation 3. NVIDIA’s NVLM 1.0 Frontier-class multimodal LLMs rivaling proprietary models Novel architecture enhancing training efficiency and reasoning 1-D tile-tagging design for high-resolution image processing Improved text-only performance after multimodal training Research 1. GRIN: GRadient-INformed MoE New approach to Mixture-of-Experts (MoE) training, incorporating sparse gradient estimation for expert routing. Developed a top-2 16×3.8B MoE model that outperforms a 7B dense model and matches a 14B dense model.\n2. Preference Tuning Survey Comprehensive overview of recent advancements in preference tuning and human feedback integration across language, speech, and vision tasks.\n3. Promptriever First retrieval model able to be prompted like a language model, achieving strong performance on standard retrieval tasks and following instructions. Curated a new 500k instance-level instruction training set from MS MARCO.\nLibraries New high-performance AI inference stack built for production, utilizing Zig, OpenXLA, MLIR, and Bazel.\nGood Reads Talk by Hamel Husain and Emil Sedgh on improving LLM apps beyond MVP:\nSystematic approach to consistently improve AI Avoiding common traps Resources for further learning ","wordCount":"349","inLanguage":"en","image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished":"2020-09-15T11:30:03Z","dateModified":"2020-09-15T11:30:03Z","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/weekly_newsletter/sept-20/"},"publisher":{"@type":"Organization","name":"Pk blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Prakyath Kantharaju's Blog (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Prakyath Kantharaju's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/prakyathkantharaju title=github.com><span>github.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/weekly_newsletter/>Weekly_newsletters</a></div><h1 class="post-title entry-hint-parent">Weekly Newsletter: Sep 20th</h1><div class=post-description>Weekly update on AI/ML - Sept 13th - Sept 20th</div><div class=post-meta><span title='2020-09-15 11:30:03 +0000 +0000'>September 15, 2020</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;349 words&nbsp;·&nbsp;Me&nbsp;|&nbsp;<a href=https://github.com/prakyathkantharaju/personal_blog/content/weekly_newsletter/sept-20.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#highlight-qwen25-family---a-comprehensive-release-of-ai-models>Highlight: Qwen2.5 Family - A Comprehensive Release of AI Models</a><ul><li><a href=#key-features>Key Features:</a></li></ul></li><li><a href=#models>Models</a><ul><li><a href=#1-qwen25-family>1. Qwen2.5 Family</a></li><li><a href=#2-mistral-ais-pixtral-12b>2. Mistral AI&rsquo;s Pixtral 12B</a></li><li><a href=#3-nvidias-nvlm-10>3. NVIDIA&rsquo;s NVLM 1.0</a></li></ul></li><li><a href=#research>Research</a><ul><li><a href=#1-grin-gradient-informed-moe>1. GRIN: GRadient-INformed MoE</a></li><li><a href=#2-preference-tuning-survey>2. Preference Tuning Survey</a></li><li><a href=#3-promptriever>3. Promptriever</a></li></ul></li><li><a href=#libraries>Libraries</a></li><li><a href=#good-reads>Good Reads</a></li></ul></nav></div></details></div><div class=post-content><h1 id=ai-newsletter---latest-developments-in-models-research-and-more>AI Newsletter - Latest Developments in Models, Research, and More<a hidden class=anchor aria-hidden=true href=#ai-newsletter---latest-developments-in-models-research-and-more>#</a></h1><h2 id=highlight-qwen25-family---a-comprehensive-release-of-ai-models>Highlight: Qwen2.5 Family - A Comprehensive Release of AI Models<a hidden class=anchor aria-hidden=true href=#highlight-qwen25-family---a-comprehensive-release-of-ai-models>#</a></h2><p>The Qwen team has unveiled their largest release ever, featuring a wide range of models for various applications.</p><h3 id=key-features>Key Features:<a hidden class=anchor aria-hidden=true href=#key-features>#</a></h3><ul><li>Qwen2.5: Models ranging from 0.5B to 72B parameters</li><li>Qwen2.5-Coder: Specialized models for coding tasks (1.5B, 7B, 32B)</li><li>Qwen2.5-Math: Models optimized for mathematical reasoning (1.5B, 7B, 72B)</li><li>Qwen2-VL-72B: Open-sourced multimodal model</li><li>Over 100 model variants, including quantized versions (GPTQ, AWQ, GGUF)</li><li>Competitive performance against proprietary models</li><li>Apache 2.0 license for most open-source models</li></ul><p>The Qwen2.5-72B-Instruct model demonstrates competitive performance against proprietary models and outperforms most open-source models in various benchmark evaluations.</p><h2 id=models>Models<a hidden class=anchor aria-hidden=true href=#models>#</a></h2><h3 id=1-qwen25-family>1. Qwen2.5 Family<a hidden class=anchor aria-hidden=true href=#1-qwen25-family>#</a></h3><ul><li>14B and 32B models outperform predecessor Qwen2-72B-Instruct</li><li>Compact 3B model achieves 68 on MMLU, surpassing Qwen1.5-14B</li><li>Qwen2.5-Coder shows competitive performance against larger code LLMs</li><li>Qwen2.5-Math supports both English and Chinese, with improved reasoning capabilities</li></ul><h3 id=2-mistral-ais-pixtral-12b>2. Mistral AI&rsquo;s Pixtral 12B<a hidden class=anchor aria-hidden=true href=#2-mistral-ais-pixtral-12b>#</a></h3><ul><li>Natively multimodal model with 400M parameter vision encoder</li><li>Supports multiple images in 128k token context window</li><li>Achieves 52.5% on MMMU reasoning benchmark</li><li>Excels in instruction following, chart understanding, and image-to-code generation</li></ul><h3 id=3-nvidias-nvlm-10>3. NVIDIA&rsquo;s NVLM 1.0<a hidden class=anchor aria-hidden=true href=#3-nvidias-nvlm-10>#</a></h3><ul><li>Frontier-class multimodal LLMs rivaling proprietary models</li><li>Novel architecture enhancing training efficiency and reasoning</li><li>1-D tile-tagging design for high-resolution image processing</li><li>Improved text-only performance after multimodal training</li></ul><h2 id=research>Research<a hidden class=anchor aria-hidden=true href=#research>#</a></h2><h3 id=1-grin-gradient-informed-moe>1. GRIN: GRadient-INformed MoE<a hidden class=anchor aria-hidden=true href=#1-grin-gradient-informed-moe>#</a></h3><p>New approach to Mixture-of-Experts (MoE) training, incorporating sparse gradient estimation for expert routing. Developed a top-2 16×3.8B MoE model that outperforms a 7B dense model and matches a 14B dense model.</p><h3 id=2-preference-tuning-survey>2. Preference Tuning Survey<a hidden class=anchor aria-hidden=true href=#2-preference-tuning-survey>#</a></h3><p>Comprehensive overview of recent advancements in preference tuning and human feedback integration across language, speech, and vision tasks.</p><h3 id=3-promptriever>3. Promptriever<a hidden class=anchor aria-hidden=true href=#3-promptriever>#</a></h3><p>First retrieval model able to be prompted like a language model, achieving strong performance on standard retrieval tasks and following instructions. Curated a new 500k instance-level instruction training set from MS MARCO.</p><h2 id=libraries>Libraries<a hidden class=anchor aria-hidden=true href=#libraries>#</a></h2><p>New high-performance AI inference stack built for production, utilizing Zig, OpenXLA, MLIR, and Bazel.</p><h2 id=good-reads>Good Reads<a hidden class=anchor aria-hidden=true href=#good-reads>#</a></h2><p>Talk by Hamel Husain and Emil Sedgh on improving LLM apps beyond MVP:</p><ol><li>Systematic approach to consistently improve AI</li><li>Avoiding common traps</li><li>Resources for further learning</li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/ai---newsletter/>AI - Newsletter</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Pk blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>