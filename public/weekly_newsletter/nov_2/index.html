<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Nov 2 Weekly Newsletter | Pk blog</title>
<meta name=keywords content="weekly_newsletter"><meta name=description content="Weekly Newsletter for Nov 2"><meta name=author content="Prakyath Kantharaju"><link rel=canonical href=https://prakyath.com/weekly_newsletter/nov_2><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/weekly_newsletter/nov_2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Nov 2 Weekly Newsletter"><meta property="og:description" content="Weekly Newsletter for Nov 2"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/weekly_newsletter/nov_2/"><meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E"><meta property="article:section" content="weekly_newsletter"><meta property="article:published_time" content="2024-11-02T11:30:03+00:00"><meta property="article:modified_time" content="2024-11-02T11:30:03+00:00"><meta property="og:site_name" content="PK's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:title content="Nov 2 Weekly Newsletter"><meta name=twitter:description content="Weekly Newsletter for Nov 2"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Weekly_newsletters","item":"http://localhost:1313/weekly_newsletter/"},{"@type":"ListItem","position":2,"name":"Nov 2 Weekly Newsletter","item":"http://localhost:1313/weekly_newsletter/nov_2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Nov 2 Weekly Newsletter","name":"Nov 2 Weekly Newsletter","description":"Weekly Newsletter for Nov 2","keywords":["weekly_newsletter"],"articleBody":"AI Newsletter - Nov 2 highlights: Smaller models are better. Layer skip decoding is better than beam search. Tokenformer is a better architecture for scaling language models. Robots can sense the touch using a new sensors developed by meta. OpenAI and Google are trading punches with new releases within minutes of each other. SmolLM 2: Smaller Models, Bigger Impact Hugging Face has unveiled SmolLM v2, a groundbreaking release pushing the boundaries of small language models. The collection features three models (135M, 360M, and 1.7B parameters) that outperform larger competitors like Qwen and Llama 3.2 across various benchmarks. Released under the Apache 2 license, these models are specifically designed for edge computing and in-browser applications.\nlink to the model: https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9\nHere is an overview of the small models and how this models fit in. Layer Skip: Meta’s Breakthrough in LLM Acceleration Meta has introduced a revolutionary decoding method called Layer Skip that significantly improves LLM performance. Key highlights:\nAchieves up to 2.16x speedup for summarization tasks Delivers 1.82x acceleration for coding tasks Provides 2.0x improvement in semantic parsing Operates by executing select layers and using subsequent ones for verification Released with inference code and fine-tuned checkpoints for Llama 3, Llama 2, and Code Llama link to the paper: https://arxiv.org/abs/2404.16710 link for more information: https://arxiv.org/abs/2404.16710\nKnowledge Graphs: A New Approach to Combat Hallucinations Recent research explores using knowledge graphs for LLM training, offering fascinating insights into hallucination reduction:\nLarger models combined with extended training periods show reduced hallucination rates Achieving a ≤5% hallucination rate demands significantly more computing power than previously estimated Interesting discovery: as models grow larger, their hallucinations become more difficult to detect Provides clearer boundaries and control over knowledge incorporation during training link for mode information: https://x.com/savvyRL/status/1844073150025515343 Tokenformer: Revolutionizing Language Model Architecture A new architecture has emerged to tackle the scaling challenges of traditional transformers:\nIntroduces token-parameter attention layer to replace linear projections Enables progressive scaling from 124M to 1.4B parameters Eliminates need for complete retraining when scaling up Achieves performance comparable to traditional transformers Available as open-source with complete code and model access link to the paper: https://arxiv.org/abs/2410.23168 Meta’s Touch-Sensitive Robotics Breakthrough Meta FAIR has announced significant advances in robotics technology:\nNew developments in touch perception and dexterity Partnerships with GelSight Inc and Wonik Robotics Focus on commercializing tactile sensing innovations Commitment to fostering an open ecosystem for AI development link for more information: https://ai.meta.com/blog/fair-robotics-open-source/?utm_source=twitter\u0026utm_medium=organic_social\u0026utm_content=video\u0026utm_campaign=fair\nSearch Integration Face-off: Google vs OpenAI Google’s Grounding with Search Google has launched search grounding for Gemini models, offering:\nReduced hallucinations through factual grounding Real-time information access Enhanced trustworthiness with supporting links Richer information through Google Search integration OpenAI’s ChatGPT Web Search OpenAI has enhanced ChatGPT with improved web search capabilities:\nFaster, more timely answers Direct links to relevant web sources Improved search accuracy and relevance ","wordCount":"463","inLanguage":"en","image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished":"2024-11-02T11:30:03Z","dateModified":"2024-11-02T11:30:03Z","author":{"@type":"Person","name":"Prakyath Kantharaju"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/weekly_newsletter/nov_2/"},"publisher":{"@type":"Organization","name":"Pk blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Prakyath Kantharaju's Blog (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Prakyath Kantharaju's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/prakyathkantharaju title=github.com><span>github.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/weekly_newsletter/>Weekly_newsletters</a></div><h1 class="post-title entry-hint-parent">Nov 2 Weekly Newsletter</h1><div class=post-description>Weekly Newsletter for Nov 2</div><div class=post-meta><span title='2024-11-02 11:30:03 +0000 +0000'>November 2, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;463 words&nbsp;·&nbsp;Prakyath Kantharaju&nbsp;|&nbsp;<a href=https://github.com/Prakyathkantharaju/prakyath.com/content/weekly_newsletter/nov_2.md/weekly_newsletter/nov_2.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#smollm-2-smaller-models-bigger-impact>SmolLM 2: Smaller Models, Bigger Impact</a></li><li><a href=#layer-skip-metas-breakthrough-in-llm-acceleration>Layer Skip: Meta&rsquo;s Breakthrough in LLM Acceleration</a></li><li><a href=#knowledge-graphs-a-new-approach-to-combat-hallucinations>Knowledge Graphs: A New Approach to Combat Hallucinations</a></li><li><a href=#tokenformer-revolutionizing-language-model-architecture>Tokenformer: Revolutionizing Language Model Architecture</a></li><li><a href=#metas-touch-sensitive-robotics-breakthrough>Meta&rsquo;s Touch-Sensitive Robotics Breakthrough</a></li><li><a href=#search-integration-face-off-google-vs-openai>Search Integration Face-off: Google vs OpenAI</a><ul><li><a href=#googles-grounding-with-search>Google&rsquo;s Grounding with Search</a></li><li><a href=#openais-chatgpt-web-search>OpenAI&rsquo;s ChatGPT Web Search</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=ai-newsletter---nov-2>AI Newsletter - Nov 2<a hidden class=anchor aria-hidden=true href=#ai-newsletter---nov-2>#</a></h1><h1 id=highlights>highlights:<a hidden class=anchor aria-hidden=true href=#highlights>#</a></h1><ul><li>Smaller models are better.</li><li>Layer skip decoding is better than beam search.</li><li>Tokenformer is a better architecture for scaling language models.</li><li>Robots can sense the touch using a new sensors developed by meta.</li><li>OpenAI and Google are trading punches with new releases within minutes of each other.</li></ul><h2 id=smollm-2-smaller-models-bigger-impact>SmolLM 2: Smaller Models, Bigger Impact<a hidden class=anchor aria-hidden=true href=#smollm-2-smaller-models-bigger-impact>#</a></h2><p>Hugging Face has unveiled SmolLM v2, a groundbreaking release pushing the boundaries of small language models. The collection features three models (135M, 360M, and 1.7B parameters) that outperform larger competitors like Qwen and Llama 3.2 across various benchmarks. Released under the Apache 2 license, these models are specifically designed for edge computing and in-browser applications.</p><p>link to the model: <a href=https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9>https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9</a></p><p><img loading=lazy src=/nov-3/smollm2.png alt=smollm2></p><p>Here is an overview of the small models and how this models fit in.
<img loading=lazy src=/nov-3/small_model_ecosystem.png alt=small_exosystem></p><h2 id=layer-skip-metas-breakthrough-in-llm-acceleration>Layer Skip: Meta&rsquo;s Breakthrough in LLM Acceleration<a hidden class=anchor aria-hidden=true href=#layer-skip-metas-breakthrough-in-llm-acceleration>#</a></h2><p>Meta has introduced a revolutionary decoding method called Layer Skip that significantly improves LLM performance. Key highlights:</p><ul><li>Achieves up to 2.16x speedup for summarization tasks</li><li>Delivers 1.82x acceleration for coding tasks</li><li>Provides 2.0x improvement in semantic parsing</li><li>Operates by executing select layers and using subsequent ones for verification</li><li>Released with inference code and fine-tuned checkpoints for Llama 3, Llama 2, and Code Llama
link to the paper: <a href=https://arxiv.org/abs/2404.16710>https://arxiv.org/abs/2404.16710</a></li></ul><p><img loading=lazy src=/nov-3/layerskip.png alt=layer_skip></p><p>link for more information: <a href=https://arxiv.org/abs/2404.16710>https://arxiv.org/abs/2404.16710</a></p><h2 id=knowledge-graphs-a-new-approach-to-combat-hallucinations>Knowledge Graphs: A New Approach to Combat Hallucinations<a hidden class=anchor aria-hidden=true href=#knowledge-graphs-a-new-approach-to-combat-hallucinations>#</a></h2><p>Recent research explores using knowledge graphs for LLM training, offering fascinating insights into hallucination reduction:</p><ul><li>Larger models combined with extended training periods show reduced hallucination rates</li><li>Achieving a ≤5% hallucination rate demands significantly more computing power than previously estimated</li><li>Interesting discovery: as models grow larger, their hallucinations become more difficult to detect</li><li>Provides clearer boundaries and control over knowledge incorporation during training
link for mode information: <a href=https://x.com/savvyRL/status/1844073150025515343>https://x.com/savvyRL/status/1844073150025515343</a></li></ul><p><img loading=lazy src=/nov-3/training_model_with_knowledge_graphs.jpeg alt=knowledge_graphs></p><h2 id=tokenformer-revolutionizing-language-model-architecture>Tokenformer: Revolutionizing Language Model Architecture<a hidden class=anchor aria-hidden=true href=#tokenformer-revolutionizing-language-model-architecture>#</a></h2><p>A new architecture has emerged to tackle the scaling challenges of traditional transformers:</p><ul><li>Introduces token-parameter attention layer to replace linear projections</li><li>Enables progressive scaling from 124M to 1.4B parameters</li><li>Eliminates need for complete retraining when scaling up</li><li>Achieves performance comparable to traditional transformers</li><li>Available as open-source with complete code and model access</li></ul><p>link to the paper: <a href=https://arxiv.org/abs/2410.23168>https://arxiv.org/abs/2410.23168</a>
<img loading=lazy src=/nov-3/tokenformer.png alt=tokenformer></p><h2 id=metas-touch-sensitive-robotics-breakthrough>Meta&rsquo;s Touch-Sensitive Robotics Breakthrough<a hidden class=anchor aria-hidden=true href=#metas-touch-sensitive-robotics-breakthrough>#</a></h2><p>Meta FAIR has announced significant advances in robotics technology:</p><ul><li>New developments in touch perception and dexterity</li><li>Partnerships with GelSight Inc and Wonik Robotics</li><li>Focus on commercializing tactile sensing innovations</li><li>Commitment to fostering an open ecosystem for AI development</li></ul><p>link for more information: <a href="https://ai.meta.com/blog/fair-robotics-open-source/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=fair">https://ai.meta.com/blog/fair-robotics-open-source/?utm_source=twitter&utm_medium=organic_social&utm_content=video&utm_campaign=fair</a></p><p><img loading=lazy src=/nov-3/meta-touch.jpg alt=meta_touch_robotics></p><h2 id=search-integration-face-off-google-vs-openai>Search Integration Face-off: Google vs OpenAI<a hidden class=anchor aria-hidden=true href=#search-integration-face-off-google-vs-openai>#</a></h2><h3 id=googles-grounding-with-search>Google&rsquo;s Grounding with Search<a hidden class=anchor aria-hidden=true href=#googles-grounding-with-search>#</a></h3><p>Google has launched search grounding for Gemini models, offering:</p><ul><li>Reduced hallucinations through factual grounding</li><li>Real-time information access</li><li>Enhanced trustworthiness with supporting links</li><li>Richer information through Google Search integration</li></ul><h3 id=openais-chatgpt-web-search>OpenAI&rsquo;s ChatGPT Web Search<a hidden class=anchor aria-hidden=true href=#openais-chatgpt-web-search>#</a></h3><p>OpenAI has enhanced ChatGPT with improved web search capabilities:</p><ul><li>Faster, more timely answers</li><li>Direct links to relevant web sources</li><li>Improved search accuracy and relevance</li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/weekly_newsletter/>Weekly_newsletter</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/weekly_newsletter/oct-26/><span class=title>Next »</span><br><span>Weekly Newsletter - October 26</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Pk blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>