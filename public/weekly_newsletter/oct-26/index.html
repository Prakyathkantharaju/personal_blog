<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Newsletter - October 26 | Pk blog</title>
<meta name=keywords content="Pytorch,LLM,Nvidia,Mistral AI"><meta name=description content="Desc Text."><meta name=author content="Prakyath Kantharaju"><link rel=canonical href=https://prakyath.com/weekly_newsletter/oct-26><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/weekly_newsletter/oct-26/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Weekly Newsletter - October 26"><meta property="og:description" content="Desc Text."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/weekly_newsletter/oct-26/"><meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E"><meta property="article:section" content="weekly_newsletter"><meta property="article:published_time" content="2024-10-26T11:30:03+00:00"><meta property="article:modified_time" content="2024-10-26T11:30:03+00:00"><meta property="og:site_name" content="PK's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:title content="Weekly Newsletter - October 26"><meta name=twitter:description content="Desc Text."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Weekly_newsletters","item":"http://localhost:1313/weekly_newsletter/"},{"@type":"ListItem","position":2,"name":"Weekly Newsletter - October 26","item":"http://localhost:1313/weekly_newsletter/oct-26/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Newsletter - October 26","name":"Weekly Newsletter - October 26","description":"Desc Text.","keywords":["Pytorch","LLM","Nvidia","Mistral AI"],"articleBody":"AI Newsletter - October 2024 Sarvam: Breaking New Ground in Indian Language AI India’s linguistic diversity has long posed a challenge for AI development, but Sarvam-1 is changing the game. This 2-billion parameter language model specifically targets 10 major Indian languages alongside English, proving that thoughtful design can outperform brute force. The model’s innovative approach tackles two critical challenges: token efficiency and data quality.\nTraditional multilingual models struggle with Indic scripts, requiring up to 8 tokens per word compared to English’s 1.4. Sarvam-1’s optimized tokenizer slashes this to 1.4-2.1 tokens across all supported languages, dramatically improving efficiency. The team also addressed the chronic shortage of high-quality Indian language data by developing advanced synthetic data generation techniques, creating a robust 2-trillion token training corpus.\nDespite its relatively modest size, Sarvam-1 is punching well above its weight. It outperforms larger models like Gemma-2-2B and Llama-3.2-3B on standard benchmarks while matching Llama 3.1 8B’s capabilities. This efficiency translates to 4-6x faster inference speeds, making it ideal for practical applications and edge devices. The model’s success demonstrates that careful optimization and focused development can often outperform sheer computational power.\nEDITOR NOTE: As an Indian, myself I am very intersted and exited for this project, it is a great step towards using multilingual models for Indian languages. I also think that this will make increase the overall quality of the model for even english data. I am very excited to see the results of this project.\nVideo Generation Breakthroughs: Mochi and Act-One The video generation landscape is seeing remarkable advancement with two significant releases. Mochi 1, released under the Apache 2.0 license, represents a state-of-the-art open video generation system that dramatically narrows the gap between closed and open systems. Its high-fidelity motion and strong prompt adherence capabilities mark a significant milestone in democratizing video generation technology.\nlink to the video: here\nMeanwhile, Runway’s Act-One introduces a novel approach to character animation. The system generates expressive character performances using just a single driving video and character image, eliminating the need for complex motion capture or rigging processes. This development in Gen-3 Alpha could revolutionize character animation workflows, making sophisticated animation techniques accessible to a broader range of creators.\nGranite 3.0: IBM’s Open Source Innovation IBM’s latest release of Granite 3.0 under the Apache 2.0 license represents a significant advancement in foundation model development. The lineup includes highly efficient 8B and 2B models that outperform similarly-sized competitors, alongside innovative 1B and 3B Mixture of Experts (MoE) models that achieve remarkable results with just 400M and 800M active parameters respectively.\nWhat sets Granite 3.0 apart is its focus on efficiency and accessibility. The 1B and 3B MoE models are specifically designed for on-device applications, making advanced AI capabilities available in resource-constrained environments. IBM has also taken the unprecedented step of providing detailed technical documentation for training an 8B model from scratch, fostering transparency and enabling broader participation in AI development.\nMeta Lingua: Democratizing LLM Training Meta has made a significant contribution to the AI community with the release of Meta Lingua, a lightweight and self-contained framework designed for training language models at scale. This PyTorch-based codebase stands out for its research-friendly architecture, making it particularly valuable for academics and researchers looking to experiment with new model architectures, loss functions, and data processing techniques.\nWhat makes Meta Lingua particularly noteworthy is its modular design philosophy. The framework uses easy-to-modify PyTorch components, enabling researchers to quickly iterate on different aspects of model development without getting bogged down in implementation complexities. This approach democratizes LLM training by providing a flexible, yet powerful foundation for exploring new ideas in language model development.\nThe release reflects Meta’s commitment to open research and collaborative AI development, providing the AI community with tools previously limited to large tech organizations. By making such sophisticated training infrastructure freely available, Meta Lingua could accelerate innovation in language model development and help bridge the gap between academic research and industrial applications.\n","wordCount":"652","inLanguage":"en","image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished":"2024-10-26T11:30:03Z","dateModified":"2024-10-26T11:30:03Z","author":{"@type":"Person","name":"Prakyath Kantharaju"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/weekly_newsletter/oct-26/"},"publisher":{"@type":"Organization","name":"Pk blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Prakyath Kantharaju's Blog (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Prakyath Kantharaju's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/prakyathkantharaju title=github.com><span>github.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/weekly_newsletter/>Weekly_newsletters</a></div><h1 class="post-title entry-hint-parent">Weekly Newsletter - October 26</h1><div class=post-description>Desc Text.</div><div class=post-meta><span title='2024-10-26 11:30:03 +0000 +0000'>October 26, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;652 words&nbsp;·&nbsp;Prakyath Kantharaju&nbsp;|&nbsp;<a href=https://github.com/prakyathkantharaju/personal_blog/content/weekly_newsletter/oct-26.md/weekly_newsletter/oct-26.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><ul><li><a href=#sarvam-breaking-new-ground-in-indian-language-ai>Sarvam: Breaking New Ground in Indian Language AI</a></li><li><a href=#video-generation-breakthroughs-mochi-and-act-one>Video Generation Breakthroughs: Mochi and Act-One</a></li><li><a href=#granite-30-ibms-open-source-innovation>Granite 3.0: IBM&rsquo;s Open Source Innovation</a></li><li><a href=#meta-lingua-democratizing-llm-training>Meta Lingua: Democratizing LLM Training</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h1 id=ai-newsletter---october-2024>AI Newsletter - October 2024<a hidden class=anchor aria-hidden=true href=#ai-newsletter---october-2024>#</a></h1><h3 id=sarvam-breaking-new-ground-in-indian-language-ai>Sarvam: Breaking New Ground in Indian Language AI<a hidden class=anchor aria-hidden=true href=#sarvam-breaking-new-ground-in-indian-language-ai>#</a></h3><p>India&rsquo;s linguistic diversity has long posed a challenge for AI development, but Sarvam-1 is changing the game. This 2-billion parameter language model specifically targets 10 major Indian languages alongside English, proving that thoughtful design can outperform brute force. The model&rsquo;s innovative approach tackles two critical challenges: token efficiency and data quality.</p><p>Traditional multilingual models struggle with Indic scripts, requiring up to 8 tokens per word compared to English&rsquo;s 1.4. Sarvam-1&rsquo;s optimized tokenizer slashes this to 1.4-2.1 tokens across all supported languages, dramatically improving efficiency. The team also addressed the chronic shortage of high-quality Indian language data by developing advanced synthetic data generation techniques, creating a robust 2-trillion token training corpus.</p><p>Despite its relatively modest size, Sarvam-1 is punching well above its weight. It outperforms larger models like Gemma-2-2B and Llama-3.2-3B on standard benchmarks while matching Llama 3.1 8B&rsquo;s capabilities. This efficiency translates to 4-6x faster inference speeds, making it ideal for practical applications and edge devices. The model&rsquo;s success demonstrates that careful optimization and focused development can often outperform sheer computational power.</p><p>EDITOR NOTE: As an Indian, myself I am very intersted and exited for this project, it is a great step towards using multilingual models for Indian languages. I also think that this will make increase the overall quality of the model for even english data. I am very excited to see the results of this project.</p><p><img loading=lazy src=/oct-25/indian_language_model.png alt=images_1></p><h3 id=video-generation-breakthroughs-mochi-and-act-one>Video Generation Breakthroughs: Mochi and Act-One<a hidden class=anchor aria-hidden=true href=#video-generation-breakthroughs-mochi-and-act-one>#</a></h3><p>The video generation landscape is seeing remarkable advancement with two significant releases. Mochi 1, released under the Apache 2.0 license, represents a state-of-the-art open video generation system that dramatically narrows the gap between closed and open systems. Its high-fidelity motion and strong prompt adherence capabilities mark a significant milestone in democratizing video generation technology.</p><p>link to the video: <a href=https://cdn.gemo.dev/results/Sequence%2001.mp4>here</a></p><p>Meanwhile, Runway&rsquo;s Act-One introduces a novel approach to character animation. The system generates expressive character performances using just a single driving video and character image, eliminating the need for complex motion capture or rigging processes. This development in Gen-3 Alpha could revolutionize character animation workflows, making sophisticated animation techniques accessible to a broader range of creators.</p><h3 id=granite-30-ibms-open-source-innovation>Granite 3.0: IBM&rsquo;s Open Source Innovation<a hidden class=anchor aria-hidden=true href=#granite-30-ibms-open-source-innovation>#</a></h3><p>IBM&rsquo;s latest release of Granite 3.0 under the Apache 2.0 license represents a significant advancement in foundation model development. The lineup includes highly efficient 8B and 2B models that outperform similarly-sized competitors, alongside innovative 1B and 3B Mixture of Experts (MoE) models that achieve remarkable results with just 400M and 800M active parameters respectively.</p><p>What sets Granite 3.0 apart is its focus on efficiency and accessibility. The 1B and 3B MoE models are specifically designed for on-device applications, making advanced AI capabilities available in resource-constrained environments. IBM has also taken the unprecedented step of providing detailed technical documentation for training an 8B model from scratch, fostering transparency and enabling broader participation in AI development.</p><p><img loading=lazy src=/oct-25/granite-3.0.png alt=images_2></p><h3 id=meta-lingua-democratizing-llm-training>Meta Lingua: Democratizing LLM Training<a hidden class=anchor aria-hidden=true href=#meta-lingua-democratizing-llm-training>#</a></h3><p>Meta has made a significant contribution to the AI community with the release of Meta Lingua, a lightweight and self-contained framework designed for training language models at scale. This PyTorch-based codebase stands out for its research-friendly architecture, making it particularly valuable for academics and researchers looking to experiment with new model architectures, loss functions, and data processing techniques.</p><p>What makes Meta Lingua particularly noteworthy is its modular design philosophy. The framework uses easy-to-modify PyTorch components, enabling researchers to quickly iterate on different aspects of model development without getting bogged down in implementation complexities. This approach democratizes LLM training by providing a flexible, yet powerful foundation for exploring new ideas in language model development.</p><p>The release reflects Meta&rsquo;s commitment to open research and collaborative AI development, providing the AI community with tools previously limited to large tech organizations. By making such sophisticated training infrastructure freely available, Meta Lingua could accelerate innovation in language model development and help bridge the gap between academic research and industrial applications.</p><p><img loading=lazy src=/oct-25/meta-lingua.png alt=images_3></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/pytorch/>Pytorch</a></li><li><a href=http://localhost:1313/tags/llm/>LLM</a></li><li><a href=http://localhost:1313/tags/nvidia/>Nvidia</a></li><li><a href=http://localhost:1313/tags/mistral-ai/>Mistral AI</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/weekly_newsletter/nov_2/><span class=title>« Prev</span><br><span>Nov 2 Weekly Newsletter</span>
</a><a class=next href=http://localhost:1313/weekly_newsletter/oct-19/><span class=title>Next »</span><br><span>Weekly Newsletter - October 19</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Pk blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>