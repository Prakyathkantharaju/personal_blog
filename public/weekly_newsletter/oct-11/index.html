<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Weekly Newsletter - Oct 11 | Pk blog</title>
<meta name=keywords content="first"><meta name=description content="Desc Text."><meta name=author content="Prakyath Kantharaju"><link rel=canonical href=https://prakyathk.com/weekly_newsletter/oct-11/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=http://localhost:1313/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/weekly_newsletter/oct-11/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Weekly Newsletter - Oct 11"><meta property="og:description" content="Desc Text."><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/weekly_newsletter/oct-11/"><meta property="og:image" content="http://localhost:1313/%3Cimage%20path/url%3E"><meta property="article:section" content="weekly_newsletter"><meta property="article:published_time" content="2024-10-11T11:30:03+00:00"><meta property="article:modified_time" content="2024-10-11T11:30:03+00:00"><meta property="og:site_name" content="PK's Blog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Cimage%20path/url%3E"><meta name=twitter:title content="Weekly Newsletter - Oct 11"><meta name=twitter:description content="Desc Text."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Weekly_newsletters","item":"http://localhost:1313/weekly_newsletter/"},{"@type":"ListItem","position":2,"name":"Weekly Newsletter - Oct 11","item":"http://localhost:1313/weekly_newsletter/oct-11/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Weekly Newsletter - Oct 11","name":"Weekly Newsletter - Oct 11","description":"Desc Text.","keywords":["first"],"articleBody":"Weekly Newsletter - October 11, 2024 AI Breakthroughs Take Center Stage in Nobel Prizes This year’s Nobel Prizes have put a spotlight on AI’s transformative impact across scientific disciplines. The Physics prize, awarded to Geoffrey Hinton and John Hopfield, celebrates their groundbreaking work on artificial neural networks – the very foundation of today’s deep learning revolution.\nMeanwhile, the Chemistry prize went to Demis Hassabis, John Jumper, and David Baker for their development of AlphaFold. This AI system has revolutionized protein structure prediction, opening new frontiers in drug discovery and biotechnology.\nARIA: A New Open-Source AI Powerhouse The AI community is buzzing about ARIA, a newly released open-source multimodal model. With its Apache 2.0 license and impressive capabilities, ARIA is poised to shake up the field:\n25.3 billion parameters (3.9 billion active) 64K token context window Handles text, images, audio, and video Innovative Mixture-of-Experts (MoE) architecture Early benchmarks show it outperforming several established models OpenAI’s o1 - Meta prompt release Link to the Playground meta prompt guide\nOpenAI Playground’s New Generate Button: Streamlining AI Development The Playground has introduced an exciting new feature: the Generate button. This tool is designed to simplify the process of creating prompts, functions, and schemas. Here’s how it works:\nPrompts: Uses meta-prompts incorporating best practices to generate or improve prompts. Schemas: Employs meta-schemas to produce valid JSON and function syntax.\nThe Generate button uses two main approaches:\nMeta-prompts for prompt generation and improvement Meta-schemas for producing valid JSON and function syntax While currently relying on these methods, there are plans to potentially integrate more advanced techniques like DSPy and “Gradient Descent” in the future.\nKey features:\nGenerates prompts and schemas from task descriptions Uses specific meta-prompts for different output types (e.g., audio) Fine-tuning LLMs: Dynamic Reasoning with DOTS Researchers continue to push the boundaries of LLM fine-tuning, with a recent breakthrough in enhancing reasoning capabilities. A new paper introduces DOTS (Dynamic Optimal reasoning Trajectories Search), an innovative approach to fine-tuning LLMs for improved reasoning:\nKey features of DOTS:\nTailors reasoning strategies to specific questions and the LLM’s capabilities Defines atomic reasoning action modules that can be combined into various trajectories Searches for optimal action trajectories through iterative exploration and evaluation Trains LLMs to plan reasoning trajectories for unseen questions The DOTS method offers two learning paradigms:\nFine-tuning an external LLM as a planner to guide the task-solving LLM Directly fine-tuning the task-solving LLM with internalized reasoning action planning Results from experiments across eight reasoning tasks show that DOTS consistently outperforms static reasoning techniques and vanilla instruction tuning. Notably, this approach enables LLMs to adjust their computation based on problem complexity, allocating deeper thinking to more challenging problems.\nThis development addresses longstanding challenges in LLM fine-tuning, such as:\nOvercoming the limitations of static, predefined reasoning actions Adapting to the specific characteristics of each question Optimizing performance for the inherent capabilities of different LLMs As the field continues to evolve, approaches like DOTS promise to significantly enhance the reasoning capabilities of large language models, opening new possibilities for AI applications across various domains. Quantization: Making AI More Accessible The push for efficient AI is driving innovative quantization techniques:\nBitNet (Microsoft): Uses 1-bit weights and quantized activations link to the paper AdderLM: Replaces floating-point multiplication with integer addition link to the paper These methods aim to reduce computational resources while maintaining performance, potentially bringing AI to more resource-constrained devices.\nTools and Frameworks: Empowering Developers New tools are streamlining AI development workflows:\nAider v0.59.0: Enhances shell-style auto-complete and YAML config, link to the repo OpenRouter: Improves LLM routing and API management link to the website Recent Papers of Interest “Benchmarking Agentic Workflow Generation” link to the paper\nIntroduces WorFBench and WorFEval for evaluating LLM workflow generation Reveals gaps between sequence and graph planning capabilities in LLMs “Towards Self-Improvement of LLMs via MCTS” link to the paper\nProposes AlphaLLM-CPL for more effective MCTS behavior distillation Shows promising results in improving LLM reasoning capabilities “Named Clinical Entity Recognition Benchmark” link to the paper\nEstablishes a standardized platform for assessing language models in healthcare NLP tasks Utilizes OMOP Common Data Model for consistency across datasets ","wordCount":"682","inLanguage":"en","image":"http://localhost:1313/%3Cimage%20path/url%3E","datePublished":"2024-10-11T11:30:03Z","dateModified":"2024-10-11T11:30:03Z","author":{"@type":"Person","name":"Prakyath Kantharaju"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/weekly_newsletter/oct-11/"},"publisher":{"@type":"Organization","name":"Pk blog","logo":{"@type":"ImageObject","url":"http://localhost:1313/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Prakyath Kantharaju's Blog (Alt + H)"><img src=http://localhost:1313/apple-touch-icon.png alt aria-label=logo height=35>Prakyath Kantharaju's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/tags/ title=tags><span>tags</span></a></li><li><a href=https://github.com/prakyathkantharaju title=github.com><span>github.com</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li><li><a href=http://localhost:1313/projects/ title=projects><span>projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/weekly_newsletter/>Weekly_newsletters</a></div><h1 class="post-title entry-hint-parent">Weekly Newsletter - Oct 11</h1><div class=post-description>Desc Text.</div><div class=post-meta><span title='2024-10-11 11:30:03 +0000 +0000'>October 11, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;682 words&nbsp;·&nbsp;Prakyath Kantharaju&nbsp;|&nbsp;<a href=https://github.com/prakyathkantharaju/personal_blog/content/weekly_newsletter/oct-11.md/weekly_newsletter/oct-11.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#ai-breakthroughs-take-center-stage-in-nobel-prizes>AI Breakthroughs Take Center Stage in Nobel Prizes</a></li><li><a href=#aria-a-new-open-source-ai-powerhouse>ARIA: A New Open-Source AI Powerhouse</a></li><li><a href=#openais-o1---meta-prompt-release>OpenAI&rsquo;s o1 - Meta prompt release</a></li><li><a href=#fine-tuning-llms-dynamic-reasoning-with-dots>Fine-tuning LLMs: Dynamic Reasoning with DOTS</a></li><li><a href=#quantization-making-ai-more-accessible>Quantization: Making AI More Accessible</a></li><li><a href=#tools-and-frameworks-empowering-developers>Tools and Frameworks: Empowering Developers</a></li><li><a href=#recent-papers-of-interest>Recent Papers of Interest</a></li></ul></nav></div></details></div><div class=post-content><h1 id=weekly-newsletter---october-11-2024>Weekly Newsletter - October 11, 2024<a hidden class=anchor aria-hidden=true href=#weekly-newsletter---october-11-2024>#</a></h1><h2 id=ai-breakthroughs-take-center-stage-in-nobel-prizes>AI Breakthroughs Take Center Stage in Nobel Prizes<a hidden class=anchor aria-hidden=true href=#ai-breakthroughs-take-center-stage-in-nobel-prizes>#</a></h2><p>This year&rsquo;s Nobel Prizes have put a spotlight on AI&rsquo;s transformative impact across scientific disciplines. The Physics prize, awarded to Geoffrey Hinton and John Hopfield, celebrates their groundbreaking work on artificial neural networks – the very foundation of today&rsquo;s deep learning revolution.</p><p>Meanwhile, the Chemistry prize went to Demis Hassabis, John Jumper, and David Baker for their development of AlphaFold. This AI system has revolutionized protein structure prediction, opening new frontiers in drug discovery and biotechnology.</p><p><img loading=lazy src=/oct-11/GZW9tFIW0AAMOPB.jpeg alt="Nobel Prizes Physics">
<img loading=lazy src=/oct-11/GZcHPXJWoAAzboh.jpeg alt="Nobel Prizes Chemistry"></p><h2 id=aria-a-new-open-source-ai-powerhouse>ARIA: A New Open-Source AI Powerhouse<a hidden class=anchor aria-hidden=true href=#aria-a-new-open-source-ai-powerhouse>#</a></h2><p>The AI community is buzzing about ARIA, a newly released open-source multimodal model. With its Apache 2.0 license and impressive capabilities, ARIA is poised to shake up the field:</p><ul><li>25.3 billion parameters (3.9 billion active)</li><li>64K token context window</li><li>Handles text, images, audio, and video</li><li>Innovative Mixture-of-Experts (MoE) architecture</li><li>Early benchmarks show it outperforming several established models</li></ul><p><img loading=lazy src=/oct-11/2024-10-11_10-40.png alt=ARIA></p><h2 id=openais-o1---meta-prompt-release>OpenAI&rsquo;s o1 - Meta prompt release<a hidden class=anchor aria-hidden=true href=#openais-o1---meta-prompt-release>#</a></h2><p><a href=https://platform.openai.com/docs/guides/prompt-generation>Link to the Playground meta prompt guide</a></p><p>OpenAI Playground&rsquo;s New Generate Button: Streamlining AI Development
The Playground has introduced an exciting new feature: the Generate button. This tool is designed to simplify the process of creating prompts, functions, and schemas. Here&rsquo;s how it works:</p><p>Prompts: Uses meta-prompts incorporating best practices to generate or improve prompts.
Schemas: Employs meta-schemas to produce valid JSON and function syntax.</p><p>The Generate button uses two main approaches:</p><ol><li><strong>Meta-prompts</strong> for prompt generation and improvement</li><li><strong>Meta-schemas</strong> for producing valid JSON and function syntax</li></ol><p>While currently relying on these methods, there are plans to potentially integrate more advanced techniques like DSPy and &ldquo;Gradient Descent&rdquo; in the future.</p><p><strong>Key features:</strong></p><ul><li>Generates prompts and schemas from task descriptions</li><li>Uses specific meta-prompts for different output types (e.g., audio)</li></ul><h2 id=fine-tuning-llms-dynamic-reasoning-with-dots>Fine-tuning LLMs: Dynamic Reasoning with DOTS<a hidden class=anchor aria-hidden=true href=#fine-tuning-llms-dynamic-reasoning-with-dots>#</a></h2><p>Researchers continue to push the boundaries of LLM fine-tuning, with a recent breakthrough in enhancing reasoning capabilities. A new paper introduces DOTS (Dynamic Optimal reasoning Trajectories Search), an innovative approach to fine-tuning LLMs for improved reasoning:</p><p>Key features of DOTS:</p><ul><li>Tailors reasoning strategies to specific questions and the LLM&rsquo;s capabilities</li><li>Defines atomic reasoning action modules that can be combined into various trajectories</li><li>Searches for optimal action trajectories through iterative exploration and evaluation</li><li>Trains LLMs to plan reasoning trajectories for unseen questions</li></ul><p>The DOTS method offers two learning paradigms:</p><ol><li>Fine-tuning an external LLM as a planner to guide the task-solving LLM</li><li>Directly fine-tuning the task-solving LLM with internalized reasoning action planning</li></ol><p>Results from experiments across eight reasoning tasks show that DOTS consistently outperforms static reasoning techniques and vanilla instruction tuning. Notably, this approach enables LLMs to adjust their computation based on problem complexity, allocating deeper thinking to more challenging problems.</p><p>This development addresses longstanding challenges in LLM fine-tuning, such as:</p><ul><li>Overcoming the limitations of static, predefined reasoning actions</li><li>Adapting to the specific characteristics of each question</li><li>Optimizing performance for the inherent capabilities of different LLMs</li></ul><p>As the field continues to evolve, approaches like DOTS promise to significantly enhance the reasoning capabilities of large language models, opening new possibilities for AI applications across various domains.
<img loading=lazy src=/oct-11/2024-10-11_10-51.png alt=DOTS></p><h2 id=quantization-making-ai-more-accessible>Quantization: Making AI More Accessible<a hidden class=anchor aria-hidden=true href=#quantization-making-ai-more-accessible>#</a></h2><p>The push for efficient AI is driving innovative quantization techniques:</p><ul><li>BitNet (Microsoft): Uses 1-bit weights and quantized activations <a href=https://arxiv.org/abs/2310.11453>link to the paper</a></li><li>AdderLM: Replaces floating-point multiplication with integer addition <a href=https://arxiv.org/pdf/2410.00907>link to the paper</a></li></ul><p>These methods aim to reduce computational resources while maintaining performance, potentially bringing AI to more resource-constrained devices.</p><h2 id=tools-and-frameworks-empowering-developers>Tools and Frameworks: Empowering Developers<a hidden class=anchor aria-hidden=true href=#tools-and-frameworks-empowering-developers>#</a></h2><p>New tools are streamlining AI development workflows:</p><ul><li>Aider v0.59.0: Enhances shell-style auto-complete and YAML config, <a href=https://github.com/aider-ai/aider>link to the repo</a></li><li>OpenRouter: Improves LLM routing and API management <a href=https://openrouter.ai/>link to the website</a></li></ul><h2 id=recent-papers-of-interest>Recent Papers of Interest<a hidden class=anchor aria-hidden=true href=#recent-papers-of-interest>#</a></h2><ol><li><p>&ldquo;Benchmarking Agentic Workflow Generation&rdquo; <a href=https://arxiv.org/abs/2410.07869>link to the paper</a></p><ul><li>Introduces WorFBench and WorFEval for evaluating LLM workflow generation</li><li>Reveals gaps between sequence and graph planning capabilities in LLMs</li></ul></li><li><p>&ldquo;Towards Self-Improvement of LLMs via MCTS&rdquo; <a href=https://arxiv.org/abs/2410.06508>link to the paper</a></p><ul><li>Proposes AlphaLLM-CPL for more effective MCTS behavior distillation</li><li>Shows promising results in improving LLM reasoning capabilities</li></ul></li><li><p>&ldquo;Named Clinical Entity Recognition Benchmark&rdquo; <a href=https://arxiv.org/abs/2410.05046>link to the paper</a></p><ul><li>Establishes a standardized platform for assessing language models in healthcare NLP tasks</li><li>Utilizes OMOP Common Data Model for consistency across datasets</li></ul></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/tags/first/>First</a></li></ul><nav class=paginav><a class=next href=http://localhost:1313/weekly_newsletter/sep_27/><span class=title>Next »</span><br><span>AI Weekly Newsletter (New open models) - Sep 27</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://localhost:1313/>Pk blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>